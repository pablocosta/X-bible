{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#cerrega todo os arquivos\n",
    "dfsNew = []\n",
    "dfsOld = []\n",
    "\n",
    "for arq in os.listdir(\"./data/PT/\"):\n",
    "    if arq.find(\"New\") > 0:\n",
    "        dfsNew.append(pd.read_csv(\"./data/PT/\"+arq, sep=\"\\t\", index_col=0))\n",
    "    elif arq.find(\"Old\") > 0:\n",
    "        dfsOld.append(pd.read_csv(\"./data/PT/\"+arq, sep=\"\\t\", index_col=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from sacremoses import MosesTokenizer\n",
    "\n",
    "def tokenize(text, lang, nGram=3):\n",
    "    entok = MosesTokenizer(lang=lang)\n",
    "    text = entok.tokenize(text, escape=False)\n",
    "    grams = []\n",
    "    for i in range(1, nGram):\n",
    "        i_grams = [\n",
    "            \" \".join(gram)\n",
    "            for gram in ngrams(text, i)\n",
    "        ]\n",
    "        grams.extend(i_grams)\n",
    "        \n",
    "    return grams\n",
    "\n",
    "def getNgramOverlap(hypothesys, references, nGram, lang):\n",
    "\n",
    "  overlaps = []\n",
    "  for h, r in zip([hypothesys], [references]):\n",
    "    if (h == \"\") or (r == \"\"):\n",
    "      overlaps.append(1.0)\n",
    "      continue\n",
    "    a = tokenize(h, lang, nGram)\n",
    "    b = tokenize(r, lang, nGram)\n",
    "\n",
    "    if len(a) >= len(b):\n",
    "      overlaps.append(len(set(a) & set(b))/len(a))\n",
    "    elif len(b) >= len(a):\n",
    "      overlaps.append(len(set(a) & set(b))/len(b))\n",
    "\n",
    "  return overlaps[0]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def getStats(dfA, dfB, lang):\n",
    "    df = dfA.merge(dfB, on=[\"livro\", \"capitulo\", \"versiculo\"])\n",
    "\n",
    "    df[\"sourceLen\"] = df[\"texto_x\"].apply(lambda x: getSizeSentece(x))\n",
    "    df[\"targetLen\"] = df[\"texto_y\"].apply(lambda x: getSizeSentece(x))\n",
    "    \n",
    "    df[\"overlap\"] = df.apply(lambda x: getNgramOverlap(x[\"texto_x\"], x[\"texto_y\"], 3, lang), axis=1)\n",
    "\n",
    "    return df\n",
    "#Matriz do novo testamento\n",
    "\n",
    "def getSizeSentece(text):\n",
    "    try:\n",
    "        return len(text.split(\" \"))\n",
    "    except:\n",
    "        return 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dfsOld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novo testamento: \n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(\"Novo testamento: \")\n",
    "import copy\n",
    "concat_df_new = []\n",
    "new = copy.deepcopy(dfsNew)\n",
    "for dfA in new:\n",
    "    new = new[1:]\n",
    "    for dfB in new:\n",
    "             \n",
    "        print(set(dfA[\"livro\"]) - set(dfB[\"livro\"]))\n",
    "        concat_df_new.append(getStats(dfA, dfB, \"pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho sem cortes:  (115364, 10)\n"
     ]
    }
   ],
   "source": [
    "dfConcat_novo = pd.concat(concat_df_new, ignore_index=False)\n",
    "print(\"tamanho sem cortes: \", dfConcat_novo.shape)\n",
    "\n",
    "dfConcat_novo[\"VERSAO\"] = \"NOVO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Velho testamento: \n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "print(\"Velho testamento: \")\n",
    "import copy\n",
    "concat_df_old = []\n",
    "old = copy.deepcopy(dfsOld)\n",
    "for dfA in old:\n",
    "    old = old[1:]\n",
    "    for dfB in old:\n",
    "             \n",
    "        print(set(dfA[\"livro\"]) - set(dfB[\"livro\"]))\n",
    "        concat_df_old.append(getStats(dfA, dfB, \"pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho sem cortes:  (223546, 10)\n"
     ]
    }
   ],
   "source": [
    "dfConcat_old = pd.concat(concat_df_old, ignore_index=False)\n",
    "print(\"tamanho sem cortes: \", dfConcat_old.shape)\n",
    "dfConcat_old[\"VERSAO\"] = \"VELHO\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.371939452952113\n",
      "27.29075860848013\n",
      "0.2873294570261173\n"
     ]
    }
   ],
   "source": [
    "df_geral = pd.concat([dfConcat_old,dfConcat_novo])\n",
    "\n",
    "print(df_geral[\"sourceLen\"].mean())\n",
    "print(df_geral[\"targetLen\"].mean())\n",
    "print(df_geral[\"overlap\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geral.dropna(inplace=True)\n",
    "df_geral = df_geral[(df_geral.sourceLen >= 5) & (df_geral.targetLen >= 5) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.368023053743702\n",
      "27.1239104980243\n",
      "0.2879330615451806\n"
     ]
    }
   ],
   "source": [
    "selRows = df_geral[(df_geral[\"livro\"] == \"Mateus\") & (df_geral[\"capitulo\"] == 1)  & (df_geral[\"versiculo\"] >= 1) & (df_geral[\"versiculo\"] <= 16)].index\n",
    "df_geral.drop(selRows, axis=0,inplace=True)\n",
    "\n",
    "selRows = df_geral[(df_geral[\"livro\"] == \"Lucas\") & (df_geral[\"capitulo\"] == 3)  & (df_geral[\"versiculo\"] >= 23) & (df_geral[\"versiculo\"] <= 38)].index\n",
    "df_geral.drop(selRows, axis=0,inplace=True)\n",
    "\n",
    "selRows = df_geral[(df_geral[\"livro\"] == \"Gênesis\") & (df_geral[\"capitulo\"] == 5)  & (df_geral[\"versiculo\"] >= 1) & (df_geral[\"versiculo\"] <= 32)].index\n",
    "df_geral.drop(selRows, axis=0,inplace=True)\n",
    "\n",
    "selRows = df_geral[(df_geral[\"livro\"] == \"Gênesis\") & (df_geral[\"capitulo\"] == 10)  & (df_geral[\"versiculo\"] >= 1) & (df_geral[\"versiculo\"] <= 32)].index\n",
    "df_geral.drop(selRows, axis=0,inplace=True)\n",
    "\n",
    "\n",
    "filter = df_geral['livro'].str.contains(\"1%20Crônicas\")\n",
    "df_geral = df_geral[~filter]\n",
    "filter = df_geral['livro'].str.contains(\"2%20Crônicas\")\n",
    "df_geral = df_geral[~filter]\n",
    "\n",
    "\n",
    "filter = df_geral['texto_x'].str.contains(\"Copyright\")\n",
    "df_geral = df_geral[~filter]\n",
    "filter = df_geral['texto_x'].str.contains(\"copyright\")\n",
    "df_geral = df_geral[~filter]\n",
    "filter = df_geral['texto_x'].str.contains(\"®\")\n",
    "df_geral = df_geral[~filter]\n",
    "\n",
    "filter = df_geral['texto_y'].str.contains(\"Copyright\")\n",
    "df_geral = df_geral[~filter]\n",
    "filter = df_geral['texto_y'].str.contains(\"copyright\")\n",
    "df_geral = df_geral[~filter]\n",
    "filter = df_geral['texto_y'].str.contains(\"®\")\n",
    "df_geral = df_geral[~filter]\n",
    "\n",
    "\n",
    "\n",
    "print(df_geral[\"sourceLen\"].mean())\n",
    "print(df_geral[\"targetLen\"].mean())\n",
    "print(df_geral[\"overlap\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estilo_x\n",
       "ARC         112612\n",
       "NTLH         84201\n",
       "NVI-PT       59471\n",
       "NVT          33027\n",
       "OL            7040\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geral.value_counts([\"estilo_x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estilo_x\n",
       "ARC         26921\n",
       "NVI-PT      26483\n",
       "NTLH        26032\n",
       "NVT         25519\n",
       "OL           6995\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geral.drop_duplicates([\"texto_x\"]).value_counts([\"estilo_x\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geral.to_csv(\"./data/FILTERED/portuguese.tsv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
