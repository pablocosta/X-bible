{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "#cerrega todo os arquivos\n",
    "dfsNew = []\n",
    "dfsOld = []\n",
    "\n",
    "for arq in os.listdir(\"./data/CHN/\"):\n",
    "    if arq.find(\"New\") > 0:\n",
    "        dfsNew.append(pd.read_csv(\"./data/CHN/\"+arq, sep=\"\\t\"))\n",
    "    elif arq.find(\"Old\") > 0:\n",
    "        dfsOld.append(pd.read_csv(\"./data/CHN/\"+arq, sep=\"\\t\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import ngrams\n",
    "from sacremoses import MosesTokenizer\n",
    "\n",
    "def tokenize(text, lang, nGram=3):\n",
    "    entok = MosesTokenizer(lang=lang)\n",
    "    text = entok.tokenize(text, escape=False)\n",
    "    grams = []\n",
    "    for i in range(1, nGram):\n",
    "        i_grams = [\n",
    "            \" \".join(gram)\n",
    "            for gram in ngrams(text, i)\n",
    "        ]\n",
    "        grams.extend(i_grams)\n",
    "        \n",
    "    return grams\n",
    "\n",
    "def getNgramOverlap(hypothesys, references, nGram, lang):\n",
    "\n",
    "  overlaps = []\n",
    "  for h, r in zip([hypothesys], [references]):\n",
    "    if (h == \"\") or (r == \"\"):\n",
    "      overlaps.append(1.0)\n",
    "      continue\n",
    "    a = tokenize(h, lang, nGram)\n",
    "    b = tokenize(r, lang, nGram)\n",
    "\n",
    "    if len(a) >= len(b) and len(a) > 0:\n",
    "      overlaps.append(len(set(a) & set(b))/len(a))\n",
    "    elif len(b) >= len(a) and len(b) > 0:\n",
    "      overlaps.append(len(set(a) & set(b))/len(b))\n",
    "    elif len(a) == 0 or len(b) == 0:\n",
    "      overlaps.append(0)\n",
    "\n",
    "  return overlaps[0]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def getStats(dfA, dfB, lang):\n",
    "    df = dfA.merge(dfB, on=[\"livro\", \"capitulo\", \"versiculo\"])\n",
    "\n",
    "    df[\"sourceLen\"] = df[\"texto_x\"].apply(lambda x: getSizeSentece(x))\n",
    "    df[\"targetLen\"] = df[\"texto_y\"].apply(lambda x: getSizeSentece(x))\n",
    "    \n",
    "    df[\"overlap\"] = df.apply(lambda x: getNgramOverlap(x[\"texto_x\"], x[\"texto_y\"], 3, lang), axis=1)\n",
    "\n",
    "    return df\n",
    "#Matriz do novo testamento\n",
    "\n",
    "def getSizeSentece(text):\n",
    "    try:\n",
    "        return len(text.split(\" \"))\n",
    "    except:\n",
    "        return 0\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Novo testamento: \n"
     ]
    }
   ],
   "source": [
    "print(\"Novo testamento: \")\n",
    "newConcat = []\n",
    "for dfA in dfsNew:\n",
    "    dfsNew = dfsNew[1:]\n",
    "    for dfB in dfsNew:\n",
    "        newConcat.append(getStats(dfA, dfB, \"zh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho sem cortes:  (221744, 10)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<=' not supported between instances of 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtamanho sem cortes: \u001b[39m\u001b[39m\"\u001b[39m, dfConcat\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      3\u001b[0m \u001b[39m#remove versiculos deseconhecidos\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m dfConcat \u001b[39m=\u001b[39m dfConcat[dfConcat[\u001b[39m\"\u001b[39;49m\u001b[39mversiculo\u001b[39;49m\u001b[39m\"\u001b[39;49m] \u001b[39m<\u001b[39;49m\u001b[39m=\u001b[39;49m \u001b[39m180\u001b[39;49m]\n\u001b[0;32m      5\u001b[0m \u001b[39m#remove textos muito difenretes\u001b[39;00m\n\u001b[0;32m      6\u001b[0m dfConcat \u001b[39m=\u001b[39m dfConcat[dfConcat[\u001b[39m\"\u001b[39m\u001b[39moverlap\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0.02\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\torch\\Lib\\site-packages\\pandas\\core\\ops\\common.py:72\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n\u001b[0;32m     70\u001b[0m other \u001b[39m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 72\u001b[0m \u001b[39mreturn\u001b[39;00m method(\u001b[39mself\u001b[39;49m, other)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\torch\\Lib\\site-packages\\pandas\\core\\arraylike.py:54\u001b[0m, in \u001b[0;36mOpsMixin.__le__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39m@unpack_zerodim_and_defer\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m__le__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__le__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[1;32m---> 54\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cmp_method(other, operator\u001b[39m.\u001b[39;49mle)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\torch\\Lib\\site-packages\\pandas\\core\\series.py:6243\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6240\u001b[0m rvalues \u001b[39m=\u001b[39m extract_array(other, extract_numpy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, extract_range\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m   6242\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 6243\u001b[0m     res_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mcomparison_op(lvalues, rvalues, op)\n\u001b[0;32m   6245\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_construct_result(res_values, name\u001b[39m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\torch\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:287\u001b[0m, in \u001b[0;36mcomparison_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    284\u001b[0m     \u001b[39mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[0;32m    286\u001b[0m \u001b[39melif\u001b[39;00m is_object_dtype(lvalues\u001b[39m.\u001b[39mdtype) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(rvalues, \u001b[39mstr\u001b[39m):\n\u001b[1;32m--> 287\u001b[0m     res_values \u001b[39m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[0;32m    289\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    290\u001b[0m     res_values \u001b[39m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\torch\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:75\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[1;34m(op, x, y)\u001b[0m\n\u001b[0;32m     73\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39mvec_compare(x\u001b[39m.\u001b[39mravel(), y\u001b[39m.\u001b[39mravel(), op)\n\u001b[0;32m     74\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 75\u001b[0m     result \u001b[39m=\u001b[39m libops\u001b[39m.\u001b[39;49mscalar_compare(x\u001b[39m.\u001b[39;49mravel(), y, op)\n\u001b[0;32m     76\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mreshape(x\u001b[39m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\pablo\\anaconda3\\envs\\torch\\Lib\\site-packages\\pandas\\_libs\\ops.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<=' not supported between instances of 'str' and 'int'"
     ]
    }
   ],
   "source": [
    "dfConcat = pd.concat(newConcat, ignore_index=False)\n",
    "print(\"tamanho sem cortes: \", dfConcat.shape)\n",
    "#remove versiculos deseconhecidos\n",
    "dfConcat = dfConcat[dfConcat[\"versiculo\"] <= 180]\n",
    "#remove textos muito difenretes\n",
    "dfConcat = dfConcat[dfConcat[\"overlap\"] > 0.02]\n",
    "#filtra sentencas curtas\n",
    "dfConcat = dfConcat[dfConcat[\"sourceLen\"] > 5]\n",
    "dfConcat = dfConcat[dfConcat[\"targetLen\"] > 5]\n",
    "\n",
    "print(\"tamanho com cortes: \", dfConcat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfConcat.to_csv(\"./data/CHN/NovoTestamentoCompleto-CHN.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Velho testamento: \n"
     ]
    }
   ],
   "source": [
    "print(\"Velho testamento: \")\n",
    "oldConcat = []\n",
    "for dfA in dfsOld:\n",
    "    dfsOld = dfsOld[1:]\n",
    "    for dfB in dfsOld:\n",
    "        oldConcat.append(getStats(dfA, dfB, \"zh\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tamanho sem cortes:  (10246620, 10)\n",
      "tamanho com cortes:  (8841448, 10)\n"
     ]
    }
   ],
   "source": [
    "dfConcat = pd.concat(oldConcat, ignore_index=False)\n",
    "print(\"tamanho sem cortes: \", dfConcat.shape)\n",
    "#remove versiculos deseconhecidos\n",
    "dfConcat = dfConcat[dfConcat[\"versiculo\"] <= 180]\n",
    "#remove textos muito difenretes\n",
    "dfConcat = dfConcat[dfConcat[\"overlap\"] > 0.02]\n",
    "#filtra sentencas curtas\n",
    "dfConcat = dfConcat[dfConcat[\"sourceLen\"] > 5]\n",
    "dfConcat = dfConcat[dfConcat[\"targetLen\"] > 5]\n",
    "\n",
    "print(\"tamanho com cortes: \", dfConcat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfConcat.to_csv(\"./data/CHN/VelhoTestamentoCompleto-CHN.tsv\", sep=\"\\t\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
